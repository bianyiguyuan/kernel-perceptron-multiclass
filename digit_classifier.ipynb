{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    data = np.loadtxt(path)\n",
    "    labels = data[:, 0].astype(int)\n",
    "    features = data[:, 1:]\n",
    "    # Normalize features\n",
    "    # features = (features - np.mean(features, axis=0)) / np.std(features, axis=0)\n",
    "    return features, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_digit(X, y):\n",
    "    img_indices = [np.argwhere(y == i)[0, 0] for i in range(10)]  \n",
    "    plt.figure(figsize=(10, 3))\n",
    "    for i in range(10):\n",
    "        plt.subplot(2, 5, i + 1)\n",
    "        img_index = img_indices[i]\n",
    "        plt.imshow(X[img_index, :].reshape(16, 16), cmap='plasma') \n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X, y, test_size=0.2, random_state=None):\n",
    "    n_samples = len(X)\n",
    "    if random_state is not None:\n",
    "        rng = np.random.default_rng(random_state)\n",
    "        indices = rng.permutation(n_samples)\n",
    "    else:\n",
    "        indices = np.random.permutation(n_samples)\n",
    "    \n",
    "    split_idx = int(n_samples * (1 - test_size))\n",
    "    train_indices = indices[:split_idx]\n",
    "    test_indices  = indices[split_idx:]\n",
    "\n",
    "    X_train, X_test = X[train_indices], X[test_indices]\n",
    "    y_train, y_test = y[train_indices], y[test_indices]\n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelPerceptron:\n",
    "    def __init__(self, K_train, epochs=3):\n",
    "        self.K_train = K_train  \n",
    "        self.epochs  = epochs\n",
    "        self.alpha   = None\n",
    "        self.y_train = None       \n",
    "\n",
    "    def fit(self, y_binary):\n",
    "        n_samples = len(y_binary)\n",
    "        self.alpha = np.zeros(n_samples)\n",
    "        self.y_train = y_binary\n",
    "\n",
    "        for _ in range(self.epochs):\n",
    "            indices = np.arange(n_samples)\n",
    "            np.random.shuffle(indices)\n",
    "            for t in indices:\n",
    "                score = np.sum(self.alpha * self.K_train[:, t])\n",
    "                prediction = np.sign(score)\n",
    "                # print(f\"Sample {t}: score={score}, prediction={prediction}, true_label={self.y_train[t]}\")\n",
    "                if prediction != self.y_train[t]:\n",
    "                    self.alpha[t] += self.y_train[t]\n",
    "                    # print(f\"Updated alpha[{t}]: {self.alpha[t]}\")\n",
    "\n",
    "    def decision_function(self, K_test):\n",
    "        return K_test.dot(self.alpha * self.y_train)\n",
    "\n",
    "    def predict(self, K_test):\n",
    "        return np.sign(self.decision_function(K_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_factory(type, d):\n",
    "    def polynomial_kernel(x, y):\n",
    "        return (x@y.T) ** d\n",
    "    \n",
    "    if type == \"polynomial\":\n",
    "        return polynomial_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ovr(K_train, y, epochs):\n",
    "    \"\"\"\n",
    "    Trains one Kernel Perceptron per unique class.\n",
    "    Returns a dict: { class_label: trained_perceptron, ... }\n",
    "    \"\"\"\n",
    "    classes = np.unique(y)\n",
    "    models = {}\n",
    "    for c in classes:\n",
    "        # Binary labels: +1 if y == c, else -1\n",
    "        y_binary = np.where(y == c, 1, -1)\n",
    "        kp = KernelPerceptron(K_train, epochs=epochs)\n",
    "        kp.fit(y_binary)\n",
    "        models[c] = kp\n",
    "\n",
    "    \n",
    "    return models\n",
    "\n",
    "def predict_ovr(K_test, models):\n",
    "    \"\"\"\n",
    "    Returns an array of predictions (class labels) for each sample in X.\n",
    "    \"\"\"\n",
    "    classes = list(models.keys())\n",
    "    all_scores = []\n",
    "    for c in classes:\n",
    "        scores_c = models[c].decision_function(K_test)\n",
    "        all_scores.append(scores_c)\n",
    "\n",
    "    all_scores = np.vstack(all_scores) \n",
    "    max_indices = np.argmax(all_scores, axis=0)\n",
    "    predicted_labels = [classes[idx] for idx in max_indices]\n",
    "    return np.array(predicted_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_error(y_true, y_pred):\n",
    "    return np.mean(y_true != y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(data_path, degrees=range(1,8), epochs=30, runs=20, test_size=0.2):\n",
    "    print(\"[INFO] Starting experiment...\")\n",
    "    \n",
    "    X, y = load_data(data_path)\n",
    "    visualize_digit(X, y)\n",
    "    \n",
    "    n_degrees = len(degrees)\n",
    "    train_errors = np.zeros((n_degrees, runs))\n",
    "    test_errors  = np.zeros((n_degrees, runs))\n",
    "    \n",
    "    for run_id in range(runs):\n",
    "        \n",
    "        print(f\"[INFO] ---------- Run {run_id+1}/{runs} ----------\")\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                            test_size=test_size,\n",
    "                                                            random_state=run_id)  \n",
    "        print(f\"      Train set size: {len(y_train)}, Test set size: {len(y_test)}\")\n",
    "\n",
    "        for i, d in enumerate(degrees):\n",
    "            # -------------- Train --------------\n",
    "            kernel = kernel_factory(\"polynomial\",d)\n",
    "            print(f\"      polynomial kernel degree: {d}\")\n",
    "            K_train = kernel(X_train, X_train)\n",
    "            \n",
    "            models = train_ovr(K_train, y_train, epochs=epochs)\n",
    "            \n",
    "            y_train_pred = predict_ovr(K_train, models)\n",
    "            train_err = classification_error(y_train, y_train_pred)\n",
    "\n",
    "            # -------------- Test --------------\n",
    "            K_test = kernel(X_test, X_train)\n",
    "            y_test_pred = predict_ovr(K_test, models)\n",
    "            test_err = classification_error(y_test, y_test_pred)\n",
    "\n",
    "            train_errors[i, run_id] = train_err\n",
    "            test_errors[i, run_id]  = test_err\n",
    "\n",
    "            print(f\"      [d={d}] train_err={train_err:.4f}, test_err={test_err:.4f}\")\n",
    "    \n",
    "    # 4. Compute mean and std\n",
    "    mean_train = np.mean(train_errors, axis=1)  # shape: (n_degrees,)\n",
    "    std_train  = np.std(train_errors, axis=1)\n",
    "    mean_test  = np.mean(test_errors, axis=1)\n",
    "    std_test   = np.std(test_errors, axis=1)\n",
    "    \n",
    "    # 5. Print results in a 2x7 table format:\n",
    "    #    Each cell: mean ± std\n",
    "    print(\"Degree |   Train Error (mean±std)   |   Test Error (mean±std)\")\n",
    "    print(\"-------------------------------------------------------------\")\n",
    "    for i, d in enumerate(degrees):\n",
    "        print(f\"  {d}    {mean_train[i]*100:.2f}±{std_train[i]*100:.2f}%    \"\n",
    "              f\"{mean_test[i]*100:.2f}±{std_test[i]*100:.2f}%\")\n",
    "\n",
    "    return (mean_train, std_train, mean_test, std_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    data_path = \"data/zipcombo.dat.txt\"  # Adjust if necessary\n",
    "    run_experiment(data_path, degrees=range(1,8), epochs=6, runs=20, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def polynomial_kernel(xi, xj, degree=2):\n",
    "    return (xi @ xj.T) ** degree\n",
    "\n",
    "class KernelPerceptron:\n",
    "    \"\"\"\n",
    "    支持 OVR (One-Versus-Rest) 和 OVO (One-Versus-One) 两种多分类策略的核感知器。\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 max_iter=30, \n",
    "                 min_iter=5, \n",
    "                 mode='ovr',\n",
    "                 kernel_function=polynomial_kernel, \n",
    "                 degree=2):\n",
    "        \"\"\"\n",
    "        初始化 KernelPerceptron\n",
    "        Args:\n",
    "            max_iter (int): 最大迭代轮数\n",
    "            min_iter (int): 最少迭代轮数，少于这个轮数时不进行早停判断\n",
    "            mode (str): 'ovr' 或 'ovo'\n",
    "            kernel_function (callable): 核函数\n",
    "            degree (int): 核函数参数（如多项式核的阶数等）\n",
    "        \"\"\"\n",
    "        self.max_iter = max_iter\n",
    "        self.min_iter = min_iter\n",
    "        self.mode = mode.lower()\n",
    "        self.kernel_function = kernel_function\n",
    "        self.degree = degree\n",
    "\n",
    "        # 下面这些成员变量在训练过程中赋值\n",
    "        self.weight_matrix = None       # 用于 OVR\n",
    "        self.pairwise_weights = dict()  # 用于 OVO, 存储 (i, j)->weights\n",
    "        self.accuracy_history = []\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "        self.num_classes = None\n",
    "\n",
    "    def fit(self, X_data, y_data):\n",
    "        \"\"\"\n",
    "        训练核感知器\n",
    "        Args:\n",
    "            X_data (np.ndarray): 训练特征, shape = (num_samples, num_features)\n",
    "            y_data (np.ndarray): 训练标签, shape = (num_samples,)\n",
    "        Returns:\n",
    "            self\n",
    "        \"\"\"\n",
    "        self.X_train = X_data\n",
    "        self.y_train = y_data\n",
    "        self.num_classes = len(np.unique(y_data))\n",
    "\n",
    "        # 预先计算完整核矩阵 K\n",
    "        kernel_matrix = self.kernel_function(X_data, X_data, self.degree)\n",
    "\n",
    "        # 根据 mode 调用不同的训练方法\n",
    "        if self.mode == 'ovr':\n",
    "            self._fit_ovr(kernel_matrix)\n",
    "        elif self.mode == 'ovo':\n",
    "            self._fit_ovo(kernel_matrix)\n",
    "        else:\n",
    "            raise ValueError(\"Mode must be either 'ovr' or 'ovo'.\")\n",
    "\n",
    "        return self\n",
    "\n",
    "    def _fit_ovr(self, kernel_matrix):\n",
    "        \"\"\"\n",
    "        OVR (One-Versus-Rest) 训练。\n",
    "        \"\"\"\n",
    "        num_samples = self.X_train.shape[0]\n",
    "        # 初始化权重矩阵： (num_classes, num_samples)\n",
    "        self.weight_matrix = np.zeros((self.num_classes, num_samples))\n",
    "        self.accuracy_history = []\n",
    "\n",
    "        # 开始迭代训练\n",
    "        for iteration in range(self.max_iter):\n",
    "            misclassify = 0\n",
    "            indices = np.arange(num_samples)\n",
    "            np.random.shuffle(indices)\n",
    "\n",
    "            for i in indices:\n",
    "                # 预测时，对每个类别都计算 (weight_matrix[class] @ kernel_matrix[i]) 并取 argmax\n",
    "                predicted_label = np.argmax(self.weight_matrix @ kernel_matrix[i, :])\n",
    "                if self.y_train[i] != predicted_label:\n",
    "                    misclassify += 1\n",
    "                    # 正确类 +1, 错误类 -1\n",
    "                    self.weight_matrix[self.y_train[i], i] += 1\n",
    "                    self.weight_matrix[predicted_label, i] -= 1\n",
    "\n",
    "            accuracy_iter = (num_samples - misclassify) / num_samples\n",
    "            self.accuracy_history.append(accuracy_iter)\n",
    "\n",
    "            # 早停判断\n",
    "            if iteration >= self.min_iter:\n",
    "                if (self.accuracy_history[-1] - self.accuracy_history[-2]) < 0.01:\n",
    "                    break\n",
    "\n",
    "    def _fit_ovo(self, kernel_matrix):\n",
    "        \"\"\"\n",
    "        OVO (One-Versus-One) 训练。\n",
    "        对每对类别 (i, j) 各自训练一个二分类感知器并储存在 self.pairwise_weights[(i,j)] 中。\n",
    "        \"\"\"\n",
    "        num_samples = self.X_train.shape[0]\n",
    "        classes = np.unique(self.y_train)\n",
    "        \n",
    "        # 字典 (i, j) -> 权重向量\n",
    "        # 注意 i < j，保证唯一性\n",
    "        for i in range(self.num_classes):\n",
    "            for j in range(i + 1, self.num_classes):\n",
    "                self.pairwise_weights[(i, j)] = np.zeros(num_samples)\n",
    "\n",
    "        self.accuracy_history = []\n",
    "\n",
    "        # 开始迭代\n",
    "        for iteration in range(self.max_iter):\n",
    "            misclassify = 0\n",
    "            indices = np.arange(num_samples)\n",
    "            np.random.shuffle(indices)\n",
    "\n",
    "            # 对所有样本做在线更新\n",
    "            for idx in indices:\n",
    "                true_label = self.y_train[idx]\n",
    "                # 遍历可能包含 true_label 的所有 (i, j) 对\n",
    "                for i in range(self.num_classes):\n",
    "                    for j in range(i+1, self.num_classes):\n",
    "                        # 如果该样本不属于这两个类别, 跳过\n",
    "                        if true_label not in (i, j):\n",
    "                            continue\n",
    "\n",
    "                        # binary_label: i -> +1, j -> -1\n",
    "                        binary_label = 1 if (true_label == i) else -1\n",
    "                        # 预测结果\n",
    "                        prediction_value = self.pairwise_weights[(i, j)] @ kernel_matrix[idx, :]\n",
    "\n",
    "                        predicted_binary_label = 1 if prediction_value >= 0 else -1\n",
    "                        if predicted_binary_label != binary_label:\n",
    "                            misclassify += 1\n",
    "                            # 感知器更新\n",
    "                            self.pairwise_weights[(i, j)][idx] += binary_label\n",
    "\n",
    "            # 计算训练集上的准确率(对全体样本进行多数投票)\n",
    "            y_pred_train = self._predict_full_ovo(kernel_matrix)\n",
    "            accuracy_iter = np.mean(y_pred_train == self.y_train)\n",
    "            self.accuracy_history.append(accuracy_iter)\n",
    "\n",
    "            # 早停判断\n",
    "            if iteration >= self.min_iter:\n",
    "                if (self.accuracy_history[-1] - self.accuracy_history[-2]) < 0.01:\n",
    "                    break\n",
    "\n",
    "    def _predict_full_ovo(self, kernel_matrix):\n",
    "        \"\"\"\n",
    "        在 OVO 模式下，对训练集中所有样本做一次完整预测，用于计算训练精度。\n",
    "        Args:\n",
    "            kernel_matrix (np.ndarray): 训练数据本身的核矩阵 (num_samples, num_samples)\n",
    "        Returns:\n",
    "            (np.ndarray): shape = (num_samples, ) 的预测标签\n",
    "        \"\"\"\n",
    "        num_samples = self.X_train.shape[0]\n",
    "        votes = np.zeros((num_samples, self.num_classes), dtype=int)\n",
    "\n",
    "        # 对每对 (i, j) 做二分类预测，并投票\n",
    "        for i in range(self.num_classes):\n",
    "            for j in range(i + 1, self.num_classes):\n",
    "                # 计算所有样本的预测分数\n",
    "                decision_values = self.pairwise_weights[(i, j)] @ kernel_matrix\n",
    "                # 正数 => i 类获票, 负数 => j 类获票\n",
    "                for idx in range(num_samples):\n",
    "                    if decision_values[idx] >= 0:\n",
    "                        votes[idx, i] += 1\n",
    "                    else:\n",
    "                        votes[idx, j] += 1\n",
    "\n",
    "        # 多数投票\n",
    "        y_pred = np.argmax(votes, axis=1)\n",
    "        return y_pred\n",
    "\n",
    "    def predict(self, X_data):\n",
    "        \"\"\"\n",
    "        对新的样本进行预测。需要用到训练时的 X_train 和对应的 kernel_function 来构建测试的核矩阵。\n",
    "\n",
    "        Args:\n",
    "            X_data (np.ndarray): 测试特征, shape = (num_test_samples, num_features)\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: 预测标签, shape = (num_test_samples, )\n",
    "        \"\"\"\n",
    "        if self.X_train is None:\n",
    "            raise ValueError(\"请先 fit 后再进行预测。\")\n",
    "\n",
    "        # 计算训练集与测试集之间的核矩阵: (num_samples, num_test_samples)\n",
    "        test_kernel_mtx = self.kernel_function(self.X_train, X_data, self.degree)\n",
    "\n",
    "        if self.mode == 'ovr':\n",
    "            # OVR 预测: 计算 weight_matrix @ test_kernel_mtx 的 argmax\n",
    "            # shape: (num_classes, num_test_samples) -> 取每列的 argmax\n",
    "            scores = self.weight_matrix @ test_kernel_mtx\n",
    "            return np.argmax(scores, axis=0)\n",
    "\n",
    "        elif self.mode == 'ovo':\n",
    "            # OVO 预测：对每对 (i, j) 做二分类投票\n",
    "            num_test = X_data.shape[0]\n",
    "            votes = np.zeros((num_test, self.num_classes), dtype=int)\n",
    "\n",
    "            for i in range(self.num_classes):\n",
    "                for j in range(i + 1, self.num_classes):\n",
    "                    # 当前 (i, j) 分类器的决策分数\n",
    "                    decision_values = self.pairwise_weights[(i, j)] @ test_kernel_mtx\n",
    "                    # 大于等于 0 -> 判为 i, 否则 j\n",
    "                    for idx in range(num_test):\n",
    "                        if decision_values[idx] >= 0:\n",
    "                            votes[idx, i] += 1\n",
    "                        else:\n",
    "                            votes[idx, j] += 1\n",
    "\n",
    "            return np.argmax(votes, axis=1)\n",
    "        else:\n",
    "            raise ValueError(\"Mode must be either 'ovr' or 'ovo'.\")\n",
    "\n",
    "\n",
    "# --------------------- 以下为辅助函数，可根据需要自行修改或拆分 --------------------- #\n",
    "def split_data_into_train_test(feature_matrix, target_vector, train_ratio=0.8):\n",
    "    \"\"\"\n",
    "    划分数据集为训练集和测试集\n",
    "    \"\"\"\n",
    "    total_samples = feature_matrix.shape[0]\n",
    "    train_set_size = int(train_ratio * total_samples)\n",
    "    shuffled_indices = np.random.permutation(total_samples)\n",
    "    training_indices = shuffled_indices[:train_set_size]\n",
    "    testing_indices = shuffled_indices[train_set_size:]\n",
    "    training_features = feature_matrix[training_indices]\n",
    "    testing_features = feature_matrix[testing_indices]\n",
    "    training_targets = target_vector[training_indices]\n",
    "    testing_targets = target_vector[testing_indices]\n",
    "    return training_features, training_targets, testing_features, testing_targets\n",
    "\n",
    "def test_error_comp(X_train, X_test, y_test, model):\n",
    "    \"\"\"\n",
    "    计算测试集错误率和(可选)混淆矩阵。此处使用封装好的 model.predict。\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    test_error = np.mean(y_pred != y_test)\n",
    "\n",
    "    # 构造混淆矩阵\n",
    "    num_classes = len(np.unique(y_test))\n",
    "    confusion_mtx = np.zeros((num_classes, num_classes))\n",
    "    for actual, predicted in zip(y_test, y_pred):\n",
    "        confusion_mtx[actual, predicted] += 1\n",
    "\n",
    "    # 行归一化\n",
    "    row_sums = confusion_mtx.sum(axis=1, keepdims=True)\n",
    "    confusion_mtx = np.nan_to_num(confusion_mtx / row_sums)\n",
    "\n",
    "    return test_error, confusion_mtx\n",
    "\n",
    "\n",
    "# --------------------- 使用示例 --------------------- #\n",
    "if __name__ == \"__main__\":\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # 随机生成数据进行演示\n",
    "    np.random.seed(0)\n",
    "    num_samples = 200\n",
    "    num_features = 5\n",
    "    num_classes = 3  # 0,1,2\n",
    "\n",
    "    X = np.random.randn(num_samples, num_features)\n",
    "    y = np.random.randint(0, num_classes, size=num_samples)\n",
    "\n",
    "    # 划分训练/测试集\n",
    "    X_train, y_train, X_test, y_test = split_data_into_train_test(X, y, train_ratio=0.8)\n",
    "\n",
    "    # ---------- 演示 OVR ----------\n",
    "    print(\"=== OVR Training ===\")\n",
    "    model_ovr = KernelPerceptron(mode='ovr', max_iter=30, min_iter=5, degree=2)\n",
    "    model_ovr.fit(X_train, y_train)\n",
    "    print(\"Final training accuracy (OVR):\", model_ovr.accuracy_history[-1])\n",
    "\n",
    "    # 测试集表现\n",
    "    test_err_ovr, conf_mtx_ovr = test_error_comp(X_train, X_test, y_test, model_ovr)\n",
    "    print(f\"OVR Test Error: {test_err_ovr:.3f}\")\n",
    "    print(\"OVR Confusion Matrix:\\n\", conf_mtx_ovr)\n",
    "\n",
    "    # ---------- 演示 OVO ----------\n",
    "    print(\"\\n=== OVO Training ===\")\n",
    "    model_ovo = KernelPerceptron(mode='ovo', max_iter=30, min_iter=5, degree=2)\n",
    "    model_ovo.fit(X_train, y_train)\n",
    "    print(\"Final training accuracy (OVO):\", model_ovo.accuracy_history[-1])\n",
    "\n",
    "    # 测试集表现\n",
    "    test_err_ovo, conf_mtx_ovo = test_error_comp(X_train, X_test, y_test, model_ovo)\n",
    "    print(f\"OVO Test Error: {test_err_ovo:.3f}\")\n",
    "    print(\"OVO Confusion Matrix:\\n\", conf_mtx_ovo)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp0078",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
